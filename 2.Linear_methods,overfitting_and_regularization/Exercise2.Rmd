---
title: "Aprendizaje Automático: Práctica 2"
author: "Braulio Vargas López"
date: "1 de abril de 2016"
lang: es
header-includes:
  - \usepackage{enumerate}
  - \usepackage{cancel}
output: 
  pdf_document:
    fig_caption: yes
    number_sections: yes
    toc: yes
---

```{r setup, include=FALSE}
library("Deriv")
library("ggplot2")
library("orthopolynom")
PI = 3.141592653589793
knitr::opts_chunk$set(echo = TRUE)

pintar <- function(puntos, funcion, intervalo, nombreGrafica, 
    colores = colors(), verFuncion = FALSE, aniadir=FALSE, colFunc = "black",k=0){
    par(bg="lightcyan")
    if(verFuncion){
        x <- y <- seq(range(puntos[,1])[1],range(puntos[,1])[2],length=100)
        z <- outer(x,y,funcion)
        contour(
            x=x, y=x, z=z,
            levels=k, las=1, drawlabels=FALSE, lwd=3, xlab="Eje X", 
            ylab="Eje y",main = nombreGrafica, add = aniadir, col = colFunc
        )
    }
    else{
        plot(intervalo, intervalo, xlab="Eje X", ylab="Eje y", type="n", 
            main = nombreGrafica)
    }

    points(puntos, col = colores, pch=19, lwd = 2)
}

simula_unif <- function(N=5,dim=2,rango=5:20){
    num = matrix(runif(N*dim, min=rango[1], max=rango[length(rango)]), 
      nrow = N, ncol = dim)
    num
}
simula_gaus <- function(N=5,dim=2,sigma=1){
    media = 0
    num = matrix(rnorm(N*dim, media, sigma), nrow = N, ncol = dim)
    num
}

simula_recta <- function(dim = -50:50, punto_1 = simula_unif(N=1,dim=2,rango=-1:1),
    punto_2 = simula_unif(N=1,dim=2,rango=-1:1), verPunto = T){
    # Por defecto, obtenemos dos puntos aleatorios dentro del intervalo,
    # pero en caso de que 
    if(verPunto){
        print("#####Punto 1")
        print(punto_1)
    
        print("#####Punto 2")
        print(punto_2)
    }

    punto_aux = c(punto_2[1]-punto_1[1], punto_2[2]-punto_1[2])

    ecuacion = c(punto_aux[2]/punto_aux[1], 
        (((-1*punto_1[1]*punto_aux[2])+(punto_1[2]*punto_aux[1]))/punto_aux[1]))
    ecuacion
}

evaluaPuntos <- function(puntosAEvaluar, func){
    etiquetas = apply(X=puntosAEvaluar, FUN=func, MARGIN=1)
    sign(etiquetas)
}

Ein <- function(datosEval, labels, resultPLA){
    ein = sign(datosEval%*%resultPLA)
    ein[ein==0]=1
    error = length(ein[ein != labels])/nrow(datosEval)
    error
}

PLA <- function(datos, label, max_iter = 3000, vini = c(0,0,0), verRecorrido = F){
    datos = cbind(rep(1, nrow(datos)), datos)
    i = 1
    mejorSol = vini
    porcentajeError = Ein(datos=datos, labels=label, resultPLA=mejorSol)
    cambiado = T
    while (i <= max_iter & cambiado){
        for(j in 1:nrow(datos)){
            signo = sign(datos[j,]%*% vini)
            if (signo == 0){
                signo = signo + 1
            }
            if(label[j] != signo){
                v_aux = vini + datos[j,]*label[j]
            }
        }
        nuevoPorcentaje = Ein(datos=datos, labels=label, resultPLA=v_aux)
        if(porcentajeError > nuevoPorcentaje){
            cat("Antiguo pocentaje de error = ",porcentajeError,"\n")
            cat("Nuevo porcentaje de error = ",nuevoPorcentaje,"\n")
            vini = v_aux
            porcentajeError = nuevoPorcentaje
        }
        else
            cambiado = F
        if(verRecorrido)
            abline(a=(-vini[1]/vini[3]),
                b=(-vini[2]/vini[3]), col="grey")
        i = i + 1
    }
    vini = (vini/vini[1])
    vini[3] = -vini[3]
    pla_result = c(vini, i, porcentajeError)
    pla_result
}

readFile <- function(fileName = "./DigitosZip/zip.train"){
    digit.train <- read.table(fileName, quote="\"", 
        comment.char="", stringsAsFactors=FALSE)

    digitos15.train = digit.train[digit.train$V1==1 | digit.train$V1==5,]
    digitos = digitos15.train[,1]
    ndigitos = nrow(digitos15.train)
    grises = array(unlist(subset(digitos15.train,select=-V1)),c(ndigitos,16,16))
    rm(digit.train)
    rm(digitos15.train)
    # grises
    digitos[digitos == 5] = -1
    list(digitos, grises)
}

getSymmetry <- function(data){
    x = abs(data-data[nrow(data):1,])
    -sum(x)
}

intensityAndSymmetry <- function(data){
    n = nrow(data)
    intensity = apply(data[1:n,,],1, mean)
    symmetry = apply(data[1:n,,],1,getSymmetry)

    result = as.matrix(cbind(intensity, symmetry))
    result
}

Regress_Lin_Effic <- function(datos, label){
    b1 = sum((datos-mean(datos)) * (label - mean(label))) / sum((datos-mean(datos))^2)
    b0 = mean(label) - b1*mean(datos)
    c(b0, b1)
}
```

# Modelos Lineales

## Gradiente Descendente. Implementar el algoritmo de gradiente descendiente.

\sffamily\bfseries

\begin{enumerate}[a)]
  \item Considerar la función no lineal de error $E(u, v) = (ue^v - 2ve^{-u})^2$. Usar gradiente descendente y minimizar esta función de error, comenzando desde el punto (u, v) = (1, 1) y usando una tasa de aprendizaje $\eta = 0,1$.
  \begin{enumerate}[1)]
    \item Calcular analíticamente y mostrar la expresión del gradiente de la función $E(u, v)$.
    \item ¿Cuántas iteraciones tarda el algoritmo en obtener por primera vez un valor de $E(u, v)$ inferior a $10^{-14}$ . (Usar flotantes de 64 bits).
    \item ¿Qué valores de $(u, v)$ obtuvo en el apartado anterior cuando alcanzo el error de $10^{-14}$.
  \end{enumerate}
  \item Considerar ahora la función $f(x,y) = x^2 + 2y^2 + 2\cdot\sin(2\pi x)\sin(2\pi y)$.
  \begin{enumerate}
    \item Usar gradiente descendente para minimizar esta función. Usar como valores iniciales $x_0= 1$, $y_0=1$, la tasa de aprendizaje $\eta = 0.01$ y un máximo de 50 iteraciones. Generar un gráfico de cómo desciende el valor de la funión con las iteraciones. Repetir el experimento pero usando $\eta = 0.1$, comentar las diferencias.
    \item Obtener el valor mínimo y los valores de las variables que lo alcanzan cuando el punto de inicio se fija: (0.1,0.1), (1,1),(-0.5,-0.5), (-1,-1). Generar una tabla con los valores obtenidos. ¿Cuál sería su conclusión sobre la verdadera dificultad de encontrar el mínimo global de una función arbitraria?
  \end{enumerate}
\end{enumerate}
\normalfont
Para realizar el gradiente de la función del apartado 1, tenemos que realizar las derivadas parciales de la función $E(u, v) = (ue^v - 2ve^{-u})^2$. Para ello, derivamos en función de $u$ y en función de $v$, obteniendo las siguientes expresiones:
  \begin{displaymath}
    E'(u) = 2(ue^v - 2ve^{-u})\cdot(e^v + 2ve^{-u})
  \end{displaymath}
  \begin{displaymath}
    E'(v) = 2(ue^v - 2ve^{-u})\cdot (ue^v - 2e^{-u})
  \end{displaymath}
  
Una vez que tenemos las derivadas, podemos hacer una implementación del gradiente descendiente para esta función, usando las derivadas calculadas anteriormente, junto con la función inicial. Esta versión la podemos ver a continuación:
\end{enumerate}

# Modelos Lineales

## Gradiente Descendente. Implementar el algoritmo de gradiente descendiente.

\sffamily\bfseries

\begin{enumerate}[a)]
  \item Considerar la función no lineal de error $E(u, v) = (ue^v - 2ve^{-u})^2$. Usar gradiente descendente y minimizar esta función de error, comenzando desde el punto (u, v) = (1, 1) y usando una tasa de aprendizaje $\eta = 0,1$.
  \begin{enumerate}[1)]
    \item Calcular analíticamente y mostrar la expresión del gradiente de la función $E(u, v)$.
    \item ¿Cuántas iteraciones tarda el algoritmo en obtener por primera vez un valor de $E(u, v)$ inferior a $10^{-14}$ . (Usar flotantes de 64 bits).
    \item ¿Qué valores de $(u, v)$ obtuvo en el apartado anterior cuando alcanzo el error de $10^{-14}$.
  \end{enumerate}
  \item Considerar ahora la función $f(x,y) = x^2 + 2y^2 + 2\cdot\sin(2\pi x)\sin(2\pi y)$.
  \begin{enumerate}
    \item Usar gradiente descendente para minimizar esta función. Usar como valores iniciales $x_0= 1$, $y_0=1$, la tasa de aprendizaje $\eta = 0.01$ y un máximo de 50 iteraciones. Generar un gráfico de cómo desciende el valor de la funión con las iteraciones. Repetir el experimento pero usando $\eta = 0.1$, comentar las diferencias.
    \item Obtener el valor mínimo y los valores de las variables que lo alcanzan cuando el punto de inicio se fija: (0.1,0.1), (1,1),(-0.5,-0.5), (-1,-1). Generar una tabla con los valores obtenidos. ¿Cuál sería su conclusión sobre la verdadera dificultad de encontrar el mínimo global de una función arbitraria?
  \end{enumerate}
\end{enumerate}
\normalfont
Para realizar el gradiente de la función del apartado 1, tenemos que realizar las derivadas parciales de la función $E(u, v) = (ue^v - 2ve^{-u})^2$. Para ello, derivamos en función de $u$ y en función de $v$, obteniendo las siguientes expresiones:
  \begin{displaymath}
    E'(u) = 2(ue^v - 2ve^{-u})\cdot(e^v + 2ve^{-u})
  \end{displaymath}
  \begin{displaymath}
    E'(v) = 2(ue^v - 2ve^{-u})\cdot (ue^v - 2e^{-u})
  \end{displaymath}
  
Una vez que tenemos las derivadas, podemos hacer una implementación del gradiente descendiente para esta función, usando las derivadas calculadas anteriormente, junto con la función inicial. Esta versión la podemos ver a continuación:
\end{enumerate}

```{r gradDesc,echo=T}
du <- function(u,v) 2*(u*exp(v) - 2*v*exp(-u))*(exp(v)+2*v*exp(-u))
dv <- function(u,v) 2*(u*exp(v) - 2*v*exp(-u))*(u*exp(v)-2*exp(-u))
fo <- function(u,v) (u*exp(v)-2*v*exp(-u))*(u*exp(v)-2*v*exp(-u))
fb <- function(x,y) x*x +2*y*y + 2*sin(2*PI*x)*sin(2*PI*y)

gradienteDescAnalitico <- function(x = 1,y = 1, eta = 0.1, 
    prec=10^(-14), maxIter = 50, showIter = F){
    xOld = 0
    yOld = 0
    nIter = 0
    # Mientras que no se haya alcanzado el error máximo que queremos o 
    # no se haya llegado al número total de iteraciones
    while (abs(du(x,y)) > prec & nIter < maxIter & 
        abs(xOld - x) > prec){
        # Guardamos los valores de X e Y
        xOld = x
        yOld = y
        # Actualizamos los valores de X e Y con las derivadas de su función
        # junto con el factor de aprendizaje
        x = xOld - eta*du(xOld,yOld)
        y = yOld - eta*dv(xOld,yOld)
        # Incrementamos el número de iteraciones
        nIter = nIter+1
    }
    # Si no queremos ver el número de iteraciones, devolverá 
    # el valor de la función en el punto, junto con el
    # valor de X y el valor de Y
    if(!showIter)
        c(fo(x,y),x, y)
    # Si queremos ver el número de iteraciones, realiza lo mismo que antes
    # pero devolviendo como último valor el número de iteraciones
    else
        c(fo(x,y),x, y, nIter)
}

```

Para ejecutar este algoritmo, realizamos la siguiente llamada para calcular el gradiente a la función anterior y como podemos ver, el resultado es el mismo, y converge en el mismo número de iteraciones.
```{r, echo=T}
gradDesc(func=fo,prec=10^(-14),showIter = T)
```

Para el apartado b, usaremos la función \texttt{gradDesc}, donde el parámetro \texttt{func} recibe la función a minimizar, y podremos mostrar los puntos que encuentra el gradiente si queremos con el flag \texttt{pintarGr} valiendo \textit{True}. Una vez hecho esto, pasamos a ver los valores que encuentra el gradiente para un $\eta=0.1$ y un $\eta=0.01$.

```{r, echo=T}
gradDesc(func=fb,eta = 0.01,pintarGr=T,nombre="Gradiente Descendiente con eta = 0.01")
```
En esta gráfica, podemos ver cómo el gradiente ha convergido y ha encontrado un mínimo, aunque haya sido un mínimo local. Esto se debe a que el valor de $\eta$ es muy pequeño, y el algoritmo dará pasos muy pequeños, con lo que se quedará ``estancado'' muy pronto. Sin embargo, con una tasa de aprendizaje de 0.1, pasa algo totalmente distinto.

```{r, echo=T}
gradDesc(func=fb,eta = 0.1,showIter=T,pintarGr=T,nombre="Gradiente Descendiente con eta = 0.1")
```
En este caso, tenemos justo lo contrario. El valor $\eta$ es muy grande y el algoritmo dará saltos de un lado para otro, siendo incapaz de converger en un mínimo, por lo que el valor de $f(x,y)$ en el mínimo, es mayor.

| Punto de inicio | $f(x,y)$ |$x$|$y$| iteraciones |
|:---------------:|:------:|:-:|:-:|:-----------:|
|(0.1,0.1)|-1.8200785|0.2438050|-0.2379258|30|
|(1,1)|0.5932694|1.2180703|0.7128120|27|
|(-0.5,-0.5)|-1.3324811|-0.7313775|-0.2378554|26|
|(-1,-1)|0.5932694|-1.2180703|-0.7128120|27|

Visto esto, podemos ver que escoger bien el punto de inicio es bastante importante para encontrar el mínimo de la función, ya que el gradiente irá descendiento hasta que se encuentre un mínimo local, y encontrar este mínimo puede depender de dónde empecemos, como se puede ver en la tabla anterior.

## Coordenada Descendente

\sffamily\bfseries
En este ejercicio comparamos la eficiencia de la técnica de optimización de ``coordenada descendente'' usando la misma función del ejercicio 1.1a. En cada iteración, tenemos dos pasos a lo largo de dos coordenadas. En el Paso-1 nos movemos a lo largo de la -coordenada u para reducir el error (suponer que se verifica una aproximación de primer orden como en gradiente descendente), y el Paso-2 es para reevaluar y movernos a lo largo de la coordenada v para reducir el error (hacer la misma hipótesis que en el paso-1). Usar una tasa de aprendizaje $\eta = 0,1$.

\begin{enumerate}
  \item ¿Qué valor de la función $E(u, v)$ se obtiene después de 15 iteraciones completas (i.e. 30 pasos) ?
  \item Establezca una comparación entre esta técnica y la técnica de gradiente descendente.
\end{enumerate}
\normalfont

A continuación podemos ver la implementación del algoritmo de la coordenada descendente:

```{r ,echo=TRUE}
coordinateDescent <- function(x = 1, y = 1, eta = 0.1, func, prec = 10^(-14),
    maxIter = 50, showIter = F, pintarGr=F, nombre = "Gradiente Descendiente"){
    df = Deriv(f=func,x=formalArgs(func))
    xOld = 0
    yOld = y
    nIter = 0
    xs = c()
    ys = c()
    while (abs(df(x,y)[1]) > prec & nIter < maxIter){
      # Almacenamos los valores de x e y en estas variables
      # auxilares para usarlas más adelante
        xOld = x
        xs = c(xs, x)
        ys = c(ys, y)
      # Calculamos el nuevo valor de X usando la derivada
        newValues = df(xOld,yOld)
        x = xOld - eta*newValues[1]
      # Calculamos el nuevo valor de Y usando la derivada, 
      # pero con el valor nuevo de X
        newValues = df(x,yOld)
        y = yOld - eta*newValues[2]
        nIter = nIter+1
    }    
    pts = cbind(xs,ys)
    if(pintarGr)
        pintar(puntos = pts, funcion = func, intervalo=c(-2,2), colores="red",
            verFuncion=T, nombreGrafica=nombre,k=1:20)
    if(!showIter)
        c(func(x,y),x, y)
    else
        c(func(x,y),x, y, nIter)
}
```

Para ver el resultado de este algoritmo al pasar 15 iteraciones, lo ejecutaremos de la siguiente forma:
```{r, echo=TRUE}
coordinateDescent(func=fo,eta = 0.1,maxIter = 15,showIter = T)
```
A su vez lo compararemos con el algoritmo anterior, usando la misma precisión y el mismo número de iteraciones:
```{r, echo=TRUE}
gradDesc(func=fo,eta = 0.1,maxIter = 15,showIter = T)
```

Como se puede ver, el resultado de la coordenada descendente es mucho mejor que el gradiente descendiente clásico, ya que el mínimo que obtiene para 15 iteraciones, es de varios órdenes de magnitud menor que el del gradiente descendiente, para esa tasa de aprendizaje y número de iteraciones, pero con una tasa de aprendizaje menor y mayor número de iteraciones obtenemos lo siguiente:
```{r, echo=TRUE}
coordinateDescent(func=fo,eta = 0.01,maxIter = 15,showIter = T)
gradDesc(func=fo,eta = 0.01,maxIter = 15,showIter = T)
coordinateDescent(func=fo,eta = 0.01,maxIter = 50,showIter = T)
gradDesc(func=fo,eta = 0.01,maxIter = 50,showIter = T)
```
Vemos que cambiando la tasa de aprendizaje, la coordenada descendente es capaz de minimizar más la función que el gradiente descendiente, ya que el mínimo que ha encontrado es menor que el gradiente descendiente en el mismo número de iteraciones, y si además, aumentamos aún más el número de iteraciones, el mínimo que encuentra es aún más pequeño, pero trabaja mucho mejor con una tasa de aprendizaje mayor.

## Método de Newton

\sffamily\bfseries
Implementar el algoritmo de minimización de Newton y aplicarlo a la función $f (x, y)$ dada en el ejercicio.1b. Desarrolle los mismos experimentos usando los mismos puntos de inicio.
\begin{enumerate}[1)]
\item Generar un gráfico de como desciende el valor de la función con las iteraciones.
\item Extraer conclusiones sobre las conductas de los algoritmos comparando la curva de decrecimiento de la función calculada en el apartado anterior y la correspondiente obtenida con gradiente descendente.
\end{enumerate}
\normalfont

La implementación del método de Newton la podemos ver a continuación:

```{r,echo=TRUE}
newtonMethod <- function(x = 0.1, y = 0.1,prec=10^{-14}, 
  func, maxIter = 50,showIter = T, pintarGr=F, nombre = "Metodo de Newton"){
  # Calculamos la derivada primera de la función
    df1 = Deriv(f=func,x=formalArgs(func))
  # Calculamos la derivada segunda de la función
    df2 = Deriv(f=func,x=formalArgs(func),nderiv=2)
  # Inicializamos los puntos y el contador de iteraciones
    xOld = 0
    yOld = 0
    xs = c()
    ys = c()
    nIter = 0
    itsTimeToStop1 = itsTimeToStop2 = itsTimeToStop3 = F
  # E iniciamos el bucle
    while(!itsTimeToStop1 & !itsTimeToStop2 & !itsTimeToStop3){
        xOld = x
        yOld = y
        
        # Calculamos el gradiente con la primera derivada
        newValues_1 = df1(xOld,yOld)
        
        # Calculamos el gradiente con la segunda derivada
        newValues_2 = df2(xOld,yOld)

        # Actualizamos los puntos
        xy = solve(matrix(newValues_2, ncol=2))%*%newValues_1

        x = xOld - xy[1,1]
        y = yOld - xy[2,1]
        
        
        if(abs(func(xOld, yOld) - func(x, y)) < prec){
          itsTimeToStop1 = T
          print("Me salgo porque estoy en un minimo local")
        }
        else if(nIter >= maxIter-1){
          itsTimeToStop2 = T
          print("Me salgo porque me he pasado de iteraciones")
        }
        else if(norm((as.matrix(df1(x,y))), type = "F") < prec){
          itsTimeToStop3 = T
          print("Me salgo porque he minimizado por debajo del umbral")
        }            
        
        xs = c(xs, nIter)
        ys = c(ys, func(x,y))
        nIter = nIter + 1
    }
    if(pintarGr){
        pts = cbind(xs,ys)
        #pintar(puntos = pts, funcion = func, intervalo=c(-2,2), colores="red",
        #    verFuncion=T, nombreGrafica=nombre)
        plot(pts, type = "l")
    }
    if(!showIter)
        c(func(x,y),x, y)
    else
        c(func(x,y),x, y, nIter)
}
```

En la función, calculamos el método de Newton para minimizar la función, es decir, hacer que $\nabla f(x) = 0$. Para esto, realizamos el proceso iterativo del bucle haciendo que los pesos se actualicen de esta manera:
\begin{equation}
  xy = \left(
\begin{matrix}
  x''_{x} & y''_x \\
  x''_{y} & y''_y
 \end{matrix}
 \right)\times\left(
 \begin{matrix}
  x'_x \\
  y'_y
 \end{matrix}
 \right)
\end{equation}


Teniendo las coordenadas que obtenemos con la segunda derivada como una matriz, podemos obtener las nuevas coordenadas como la diferencia de la coordenada anterior con el resultado de la operación anterior, quedando lo siguiente:

\begin{equation*}
\begin{matrix}
  x_{new} = x_{old} - xy_{1,1}\\
  y_{new} = y_{old} - xy_{2,1}
\end{matrix}
\end{equation*}

Con esto, el método de Newthon minimizará la función mientras que no hayamos encontrado un ``mínimo local'' o \textit{flat zone}, hayamos llegado al máximo de iteraciones, o hayamos minimizado más que un $\varepsilon$.

Un ejemplo de ejecución para la función del ejercicio 1b es el siguiente, con los parámetros por defecto:
```{r,echo=T}
newtonMethod(func = fb, pintarGr = T)
```

En la gráfica, podemos ver como el algoritmo no es capaz de converger en ningún momento, ya que no cumple ninguna de las condiciones de parada, y se ve como el mínimo va ``danzando'' de un punto a otro de la función, hasta que llega al máximo de iteraciones con un valor de 87.62 aproximadamente, para un punto de inicio (0.1,0.1).

Para comparar con los otros algoritmos, vamos a mostrar la curva que realiza este algoritmo, y veremos los resultados más adelante en una tabla. 
```{r, echo=T}
newtonMethod(x = 1, y = 1, func = fb, pintarGr = T, nombre = "P. inicio = (1,1)")
newtonMethod(x = -0.5, y = -0.5, func = fb, pintarGr = T, nombre = "P. inicio = (-0.5,-0.5)")
newtonMethod(x = -1, y = -1, func = fb, pintarGr = T, nombre = "P. inicio = (-1,-1)")
```
| Punto de inicio | $f_{GD}(x,y)$ | iteraciones |$f_{Nw}(x,y)$ | iteraciones |
|:---------------:|:------|:-|--:|-----------:|
|(0.1, 0.1)|-1.8200785|17|87.618256|50|
|(1, 1)|0.5932694|12|2.9004046|4|
|(-0.5, -0.5)|-1.3324811|13| 0.7254821|4|
|(-1, -1)|0.5932694|12|2.9004046|4|

Como podemos ver en la tabla, el poder de minimización del método de Newton es un poco menor que el del gradiente descendiente, pero tiene la ventaja de que realiza menos iteraciones que el gradiente descendiente, y nos da un mínimo con cierta calidad, pero muy dependiente del punto de inicio de la función.
