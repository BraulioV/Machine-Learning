---
title: "Aprendizaje Automático: Práctica 2"
author: "Braulio Vargas López"
date: "1 de abril de 2016"
lang: es
header-includes:
  - \usepackage{enumerate}
  - \usepackage{cancel}
output: 
  pdf_document:
    fig_caption: yes
    number_sections: yes
    toc: yes
---

```{r setup, include=FALSE}
library("Deriv")
library("ggplot2")
library("orthopolynom")
PI = 3.141592653589793
knitr::opts_chunk$set(echo = TRUE)

pintar <- function(puntos, funcion, intervalo, nombreGrafica, 
    colores = colors(), verFuncion = FALSE, aniadir=FALSE, colFunc = "black",k=0){
    par(bg="lightcyan")
    if(verFuncion){
        x <- y <- seq(range(puntos[,1])[1],range(puntos[,1])[2],length=100)
        z <- outer(x,y,funcion)
        contour(
            x=x, y=x, z=z,
            levels=k, las=1, drawlabels=FALSE, lwd=3, xlab="Eje X", 
            ylab="Eje y",main = nombreGrafica, add = aniadir, col = colFunc
        )
    }
    else{
        plot(intervalo, intervalo, xlab="Eje X", ylab="Eje y", type="n", 
            main = nombreGrafica)
    }

    points(puntos, col = colores, pch=19, lwd = 2)
}

simula_unif <- function(N=5,dim=2,rango=5:20){
    num = matrix(runif(N*dim, min=rango[1], max=rango[length(rango)]), 
      nrow = N, ncol = dim)
    num
}
simula_gaus <- function(N=5,dim=2,sigma=1){
    media = 0
    num = matrix(rnorm(N*dim, media, sigma), nrow = N, ncol = dim)
    num
}

simula_recta <- function(dim = -50:50, punto_1 = simula_unif(N=1,dim=2,rango=-1:1),
    punto_2 = simula_unif(N=1,dim=2,rango=-1:1), verPunto = T){
    # Por defecto, obtenemos dos puntos aleatorios dentro del intervalo,
    # pero en caso de que 
    if(verPunto){
        print("#####Punto 1")
        print(punto_1)
    
        print("#####Punto 2")
        print(punto_2)
    }

    punto_aux = c(punto_2[1]-punto_1[1], punto_2[2]-punto_1[2])

    ecuacion = c(punto_aux[2]/punto_aux[1], 
        (((-1*punto_1[1]*punto_aux[2])+(punto_1[2]*punto_aux[1]))/punto_aux[1]))
    ecuacion
}

evaluaPuntos <- function(puntosAEvaluar, func){
    etiquetas = apply(X=puntosAEvaluar, FUN=func, MARGIN=1)
    sign(etiquetas)
}

Ein <- function(datosEval, labels, resultPLA){
    ein = sign(datosEval%*%resultPLA)
    ein[ein==0]=1
    error = length(ein[ein != labels])/nrow(datosEval)
    error
}

PLA <- function(datos, label, max_iter = 3000, vini = c(0,0,0), verRecorrido = F){
    datos = cbind(rep(1, nrow(datos)), datos)
    i = 1
    mejorSol = vini
    porcentajeError = Ein(datos=datos, labels=label, resultPLA=mejorSol)
    cambiado = T
    while (i <= max_iter & cambiado){
        for(j in 1:nrow(datos)){
            signo = sign(datos[j,]%*% vini)
            if (signo == 0){
                signo = signo + 1
            }
            if(label[j] != signo){
                v_aux = vini + datos[j,]*label[j]
            }
        }
        nuevoPorcentaje = Ein(datos=datos, labels=label, resultPLA=v_aux)
        if(porcentajeError > nuevoPorcentaje){
            cat("Antiguo pocentaje de error = ",porcentajeError,"\n")
            cat("Nuevo porcentaje de error = ",nuevoPorcentaje,"\n")
            vini = v_aux
            porcentajeError = nuevoPorcentaje
        }
        else
            cambiado = F
        if(verRecorrido)
            abline(a=(-vini[1]/vini[3]),
                b=(-vini[2]/vini[3]), col="grey")
        i = i + 1
    }
    vini = (vini/vini[1])
    vini[3] = -vini[3]
    pla_result = c(vini, i, porcentajeError)
    pla_result
}

readFile <- function(fileName = "./DigitosZip/zip.train"){
    digit.train <- read.table(fileName, quote="\"", 
        comment.char="", stringsAsFactors=FALSE)

    digitos15.train = digit.train[digit.train$V1==1 | digit.train$V1==5,]
    digitos = digitos15.train[,1]
    ndigitos = nrow(digitos15.train)
    grises = array(unlist(subset(digitos15.train,select=-V1)),c(ndigitos,16,16))
    rm(digit.train)
    rm(digitos15.train)
    # grises
    digitos[digitos == 5] = -1
    list(digitos, grises)
}

getSymmetry <- function(data){
    x = abs(data-data[nrow(data):1,])
    -sum(x)
}

intensityAndSymmetry <- function(data){
    n = nrow(data)
    intensity = apply(data[1:n,,],1, mean)
    symmetry = apply(data[1:n,,],1,getSymmetry)

    result = as.matrix(cbind(intensity, symmetry))
    result
}

Regress_Lin_Effic <- function(datos, label){
    b1 = sum((datos-mean(datos)) * (label - mean(label))) / sum((datos-mean(datos))^2)
    b0 = mean(label) - b1*mean(datos)
    c(b0, b1)
}
```

# Modelos Lineales

## Gradiente Descendente. Implementar el algoritmo de gradiente descendiente.

\sffamily\bfseries

\begin{enumerate}[a)]
  \item Considerar la función no lineal de error $E(u, v) = (ue^v - 2ve^{-u})^2$. Usar gradiente descendente y minimizar esta función de error, comenzando desde el punto (u, v) = (1, 1) y usando una tasa de aprendizaje $\eta = 0,1$.
  \begin{enumerate}[1)]
    \item Calcular analíticamente y mostrar la expresión del gradiente de la función $E(u, v)$.
    \item ¿Cuántas iteraciones tarda el algoritmo en obtener por primera vez un valor de $E(u, v)$ inferior a $10^{-14}$ . (Usar flotantes de 64 bits).
    \item ¿Qué valores de $(u, v)$ obtuvo en el apartado anterior cuando alcanzo el error de $10^{-14}$.
  \end{enumerate}
  \item Considerar ahora la función $f(x,y) = x^2 + 2y^2 + 2\cdot\sin(2\pi x)\sin(2\pi y)$.
  \begin{enumerate}
    \item Usar gradiente descendente para minimizar esta función. Usar como valores iniciales $x_0= 1$, $y_0=1$, la tasa de aprendizaje $\eta = 0.01$ y un máximo de 50 iteraciones. Generar un gráfico de cómo desciende el valor de la funión con las iteraciones. Repetir el experimento pero usando $\eta = 0.1$, comentar las diferencias.
    \item Obtener el valor mínimo y los valores de las variables que lo alcanzan cuando el punto de inicio se fija: (0.1,0.1), (1,1),(-0.5,-0.5), (-1,-1). Generar una tabla con los valores obtenidos. ¿Cuál sería su conclusión sobre la verdadera dificultad de encontrar el mínimo global de una función arbitraria?
  \end{enumerate}
\end{enumerate}
\normalfont
Para realizar el gradiente de la función del apartado 1, tenemos que realizar las derivadas parciales de la función $E(u, v) = (ue^v - 2ve^{-u})^2$. Para ello, derivamos en función de $u$ y en función de $v$, obteniendo las siguientes expresiones:
  \begin{displaymath}
    E'(u) = 2(ue^v - 2ve^{-u})\cdot(e^v + 2ve^{-u})
  \end{displaymath}
  \begin{displaymath}
    E'(v) = 2(ue^v - 2ve^{-u})\cdot (ue^v - 2e^{-u})
  \end{displaymath}
  
Una vez que tenemos las derivadas, podemos hacer una implementación del gradiente descendiente para esta función, usando las derivadas calculadas anteriormente, junto con la función inicial. Esta versión la podemos ver a continuación:
\end{enumerate}

# Modelos Lineales

## Gradiente Descendente. Implementar el algoritmo de gradiente descendiente.

\sffamily\bfseries

\begin{enumerate}[a)]
  \item Considerar la función no lineal de error $E(u, v) = (ue^v - 2ve^{-u})^2$. Usar gradiente descendente y minimizar esta función de error, comenzando desde el punto (u, v) = (1, 1) y usando una tasa de aprendizaje $\eta = 0,1$.
  \begin{enumerate}[1)]
    \item Calcular analíticamente y mostrar la expresión del gradiente de la función $E(u, v)$.
    \item ¿Cuántas iteraciones tarda el algoritmo en obtener por primera vez un valor de $E(u, v)$ inferior a $10^{-14}$ . (Usar flotantes de 64 bits).
    \item ¿Qué valores de $(u, v)$ obtuvo en el apartado anterior cuando alcanzo el error de $10^{-14}$.
  \end{enumerate}
  \item Considerar ahora la función $f(x,y) = x^2 + 2y^2 + 2\cdot\sin(2\pi x)\sin(2\pi y)$.
  \begin{enumerate}
    \item Usar gradiente descendente para minimizar esta función. Usar como valores iniciales $x_0= 1$, $y_0=1$, la tasa de aprendizaje $\eta = 0.01$ y un máximo de 50 iteraciones. Generar un gráfico de cómo desciende el valor de la funión con las iteraciones. Repetir el experimento pero usando $\eta = 0.1$, comentar las diferencias.
    \item Obtener el valor mínimo y los valores de las variables que lo alcanzan cuando el punto de inicio se fija: (0.1,0.1), (1,1),(-0.5,-0.5), (-1,-1). Generar una tabla con los valores obtenidos. ¿Cuál sería su conclusión sobre la verdadera dificultad de encontrar el mínimo global de una función arbitraria?
  \end{enumerate}
\end{enumerate}
\normalfont
Para realizar el gradiente de la función del apartado 1, tenemos que realizar las derivadas parciales de la función $E(u, v) = (ue^v - 2ve^{-u})^2$. Para ello, derivamos en función de $u$ y en función de $v$, obteniendo las siguientes expresiones:
  \begin{displaymath}
    E'(u) = 2(ue^v - 2ve^{-u})\cdot(e^v + 2ve^{-u})
  \end{displaymath}
  \begin{displaymath}
    E'(v) = 2(ue^v - 2ve^{-u})\cdot (ue^v - 2e^{-u})
  \end{displaymath}
  
Una vez que tenemos las derivadas, podemos hacer una implementación del gradiente descendiente para esta función, usando las derivadas calculadas anteriormente, junto con la función inicial. Esta versión la podemos ver a continuación:
\end{enumerate}

```{r gradDesc,echo=T}
du <- function(u,v) 2*(u*exp(v) - 2*v*exp(-u))*(exp(v)+2*v*exp(-u))
dv <- function(u,v) 2*(u*exp(v) - 2*v*exp(-u))*(u*exp(v)-2*exp(-u))
fo <- function(u,v) (u*exp(v)-2*v*exp(-u))*(u*exp(v)-2*v*exp(-u))
fb <- function(x,y) x*x +2*y*y + 2*sin(2*PI*x)*sin(2*PI*y)

gradienteDescAnalitico <- function(x = 1,y = 1, eta = 0.1, 
    prec=10^(-14), maxIter = 50, showIter = F){
    xOld = 0
    yOld = 0
    nIter = 0
    # Mientras que no se haya alcanzado el error máximo que queremos o 
    # no se haya llegado al número total de iteraciones
    while (abs(du(x,y)) > prec & nIter < maxIter & 
        abs(xOld - x) > prec){
        # Guardamos los valores de X e Y
        xOld = x
        yOld = y
        # Actualizamos los valores de X e Y con las derivadas de su función
        # junto con el factor de aprendizaje
        x = xOld - eta*du(xOld,yOld)
        y = yOld - eta*dv(xOld,yOld)
        # Incrementamos el número de iteraciones
        nIter = nIter+1
    }
    # Si no queremos ver el número de iteraciones, devolverá 
    # el valor de la función en el punto, junto con el
    # valor de X y el valor de Y
    if(!showIter)
        c(fo(x,y),x, y)
    # Si queremos ver el número de iteraciones, realiza lo mismo que antes
    # pero devolviendo como último valor el número de iteraciones
    else
        c(fo(x,y),x, y, nIter)
}

```

Para ejecutar este algoritmo, realizamos la siguiente llamada para calcular el gradiente a la función anterior y como podemos ver, el resultado es el mismo, y converge en el mismo número de iteraciones.
```{r, echo=T}
gradDesc(func=fo,prec=10^(-14),showIter = T)
```

Para el apartado b, usaremos la función \texttt{gradDesc}, donde el parámetro \texttt{func} recibe la función a minimizar, y podremos mostrar los puntos que encuentra el gradiente si queremos con el flag \texttt{pintarGr} valiendo \textit{True}. Una vez hecho esto, pasamos a ver los valores que encuentra el gradiente para un $\eta=0.1$ y un $\eta=0.01$.

```{r, echo=T}
gradDesc(func=fb,eta = 0.01,pintarGr=T,nombre="Gradiente Descendiente con eta = 0.01")
```
En esta gráfica, podemos ver cómo el gradiente ha convergido y ha encontrado un mínimo, aunque haya sido un mínimo local. Esto se debe a que el valor de $\eta$ es muy pequeño, y el algoritmo dará pasos muy pequeños, con lo que se quedará ``estancado'' muy pronto. Sin embargo, con una tasa de aprendizaje de 0.1, pasa algo totalmente distinto.

```{r, echo=T}
gradDesc(func=fb,eta = 0.1,showIter=T,pintarGr=T,nombre="Gradiente Descendiente con eta = 0.1")
```
En este caso, tenemos justo lo contrario. El valor $\eta$ es muy grande y el algoritmo dará saltos de un lado para otro, siendo incapaz de converger en un mínimo, por lo que el valor de $f(x,y)$ en el mínimo, es mayor.

| Punto de inicio | $f(x,y)$ |$x$|$y$| iteraciones |
|:---------------:|:------:|:-:|:-:|:-----------:|
|(0.1,0.1)|-1.8200785|0.2438050|-0.2379258|30|
|(1,1)|0.5932694|1.2180703|0.7128120|27|
|(-0.5,-0.5)|-1.3324811|-0.7313775|-0.2378554|26|
|(-1,-1)|0.5932694|-1.2180703|-0.7128120|27|

Visto esto, podemos ver que escoger bien el punto de inicio es bastante importante para encontrar el mínimo de la función, ya que el gradiente irá descendiento hasta que se encuentre un mínimo local, y encontrar este mínimo puede depender de dónde empecemos, como se puede ver en la tabla anterior.

## Coordenada Descendente

\sffamily\bfseries
En este ejercicio comparamos la eficiencia de la técnica de optimización de ``coordenada descendente'' usando la misma función del ejercicio 1.1a. En cada iteración, tenemos dos pasos a lo largo de dos coordenadas. En el Paso-1 nos movemos a lo largo de la -coordenada u para reducir el error (suponer que se verifica una aproximación de primer orden como en gradiente descendente), y el Paso-2 es para reevaluar y movernos a lo largo de la coordenada v para reducir el error (hacer la misma hipótesis que en el paso-1). Usar una tasa de aprendizaje $\eta = 0,1$.

\begin{enumerate}
  \item ¿Qué valor de la función $E(u, v)$ se obtiene después de 15 iteraciones completas (i.e. 30 pasos) ?
  \item Establezca una comparación entre esta técnica y la técnica de gradiente descendente.
\end{enumerate}
\normalfont

A continuación podemos ver la implementación del algoritmo de la coordenada descendente:

```{r ,echo=TRUE}
coordinateDescent <- function(x = 1, y = 1, eta = 0.1, func, prec = 10^(-14),
    maxIter = 50, showIter = F, pintarGr=F, nombre = "Gradiente Descendiente"){
    df = Deriv(f=func,x=formalArgs(func))
    xOld = 0
    yOld = y
    nIter = 0
    xs = c()
    ys = c()
    while (abs(df(x,y)[1]) > prec & nIter < maxIter){
      # Almacenamos los valores de x e y en estas variables
      # auxilares para usarlas más adelante
        xOld = x
        xs = c(xs, x)
        ys = c(ys, y)
      # Calculamos el nuevo valor de X usando la derivada
        newValues = df(xOld,yOld)
        x = xOld - eta*newValues[1]
      # Calculamos el nuevo valor de Y usando la derivada, 
      # pero con el valor nuevo de X
        newValues = df(x,yOld)
        y = yOld - eta*newValues[2]
        nIter = nIter+1
    }    
    pts = cbind(xs,ys)
    if(pintarGr)
        pintar(puntos = pts, funcion = func, intervalo=c(-2,2), colores="red",
            verFuncion=T, nombreGrafica=nombre,k=1:20)
    if(!showIter)
        c(func(x,y),x, y)
    else
        c(func(x,y),x, y, nIter)
}
```

Para ver el resultado de este algoritmo al pasar 15 iteraciones, lo ejecutaremos de la siguiente forma:
```{r, echo=TRUE}
coordinateDescent(func=fo,eta = 0.1,maxIter = 15,showIter = T)
```
A su vez lo compararemos con el algoritmo anterior, usando la misma precisión y el mismo número de iteraciones:
```{r, echo=TRUE}
gradDesc(func=fo,eta = 0.1,maxIter = 15,showIter = T)
```

Como se puede ver, el resultado de la coordenada descendente es mucho mejor que el gradiente descendiente clásico, ya que el mínimo que obtiene para 15 iteraciones, es de varios órdenes de magnitud menor que el del gradiente descendiente, para esa tasa de aprendizaje y número de iteraciones, pero con una tasa de aprendizaje menor y mayor número de iteraciones obtenemos lo siguiente:
```{r, echo=TRUE}
coordinateDescent(func=fo,eta = 0.01,maxIter = 15,showIter = T)
gradDesc(func=fo,eta = 0.01,maxIter = 15,showIter = T)
coordinateDescent(func=fo,eta = 0.01,maxIter = 50,showIter = T)
gradDesc(func=fo,eta = 0.01,maxIter = 50,showIter = T)
```
Vemos que cambiando la tasa de aprendizaje, la coordenada descendente es capaz de minimizar más la función que el gradiente descendiente, ya que el mínimo que ha encontrado es menor que el gradiente descendiente en el mismo número de iteraciones, y si además, aumentamos aún más el número de iteraciones, el mínimo que encuentra es aún más pequeño, pero trabaja mucho mejor con una tasa de aprendizaje mayor.
